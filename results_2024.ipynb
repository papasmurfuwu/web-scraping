{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief Overview for thought process behind code: \n",
    "1. Create two functions, one for scrapping normal pages and one for the two special pages (Alaska and American Samoa)\n",
    "2. Loop over all pages to scrape required data\n",
    "3. After collecting all data, append to one list, then create dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libararies from selenium/ beautifulsoup/ pandas\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (123.0.6312.58) detected in PATH at c:\\Users\\quent\\repos\\ISOM3400\\Assignments\\chromedriver.exe might not be compatible with the detected chrome version (124.0.6367.93); currently, chromedriver 124.0.6367.91 is recommended for chrome 124.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "# Setting up Chromedriver  \n",
    "service = Service() \n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out counties that are present for both Demoratic and Republican \n",
    "states_democratic = ['Alabama', 'American Samoa', 'Arkansas', 'California', 'Colorado', \n",
    "                     'Iowa', 'Maine', 'Massachusetts', 'Minnesota', 'North Carolina',\n",
    "                     'Oklahoma', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia']\n",
    "states_republican = ['Alabama', 'Alaska', 'Arkansas', 'California', 'Colorado',\n",
    "                     'Maine', 'Massachusetts', 'Minnesota', 'North Carolina', \n",
    "                     'Oklahoma', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia']\n",
    "states_both = [state.lower() for state in states_democratic if state in states_republican]\n",
    "states_both.insert(4, 'iowa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for scrapping normal pages \n",
    "def scrape_election_page(state_nm):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    columns = soup.select('div.tile-h_ymFU.cnn-pcl-13b0kh1[data-testid=\"card\"]')\n",
    "    county_name_ls = soup.select(\"div.tile-h_ymFU.cnn-pcl-13b0kh1[data-testid='card'] > article > div.header-container-1LzJY9 > h2.header-2-AOgLYo\")\n",
    "\n",
    "    # Add in delegate numbers from table above\n",
    "    delegate_rows = soup.select('tr.cnn-pcl-1me6450.isWinner-3g_AYM')\n",
    "    candidate_delegates = {} \n",
    "    for row in delegate_rows:\n",
    "        name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "        candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "        delegate_element = row.select_one('td[data-testid=\"delegates\"]')\n",
    "        delegates = int(delegate_element.get_text(strip=True)) if delegate_element else 0\n",
    "\n",
    "        # Initialize the candidate in the dictionary if it doesn't exist\n",
    "        if candidate not in candidate_delegates:\n",
    "            candidate_delegates[candidate] = 0\n",
    "            \n",
    "        # Store the candidate-delegate pair in the dictionary\n",
    "        candidate_delegates[candidate] += delegates\n",
    "\n",
    "\n",
    "    for i, column in enumerate(columns):  \n",
    "        table = column.select_one('table.cnn-pcl-1me6450')\n",
    "        rows = table.select('tr.cnn-pcl-1me6450')\n",
    "        county_name = county_name_ls[i].text\n",
    "\n",
    "        for row in rows:\n",
    "            state = ''\n",
    "            # Handle word for 2-word counties, which is only North Carolina \n",
    "            if state_nm == 'north-carolina': \n",
    "                state = \"North Carolina\"\n",
    "            else: \n",
    "                state = soup.select_one('h2.header-2-AOgLYo.cnn-pcl-xk8c6r').get_text().split()[-1]\n",
    "\n",
    "            name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "            candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "            party_element = row.select_one('span[data-testid=\"party-label\"]')\n",
    "            party = party_element.get_text(strip=True).split(',')[0] if party_element else None\n",
    "\n",
    "            incumbent = 'Incumbent' in party_element.get_text(strip=True) if party_element else False\n",
    "            incumbent_status = 'Yes' if incumbent else 'No'\n",
    "\n",
    "            vote_percent_element = row.select_one('td[data-testid=\"votepercent\"]')\n",
    "            percentage = vote_percent_element.get_text(strip=True) if vote_percent_element else None\n",
    "            \n",
    "            vote_count_element = row.select_one('span[data-testid=\"votes\"]')\n",
    "            votes = 0\n",
    "            if vote_count_element:\n",
    "                try:\n",
    "                    votes = int(vote_count_element.get_text(strip=True).replace(',', ''))\n",
    "                except ValueError:\n",
    "                    votes = 0\n",
    "            \n",
    "            winner = 'Yes' if incumbent_status == 'Yes' else 'No'\n",
    "            delegates = candidate_delegates.get(candidate, 0)\n",
    "\n",
    "\n",
    "            if candidate: # Generate and return a dictionary for each row \n",
    "                yield {\n",
    "                    'State': state,\n",
    "                    'County': county_name,\n",
    "                    'Candidate': candidate,\n",
    "                    'Party': party,\n",
    "                    'Incumbent': incumbent_status,\n",
    "                    'Votes': votes,\n",
    "                    'Percentage': percentage,\n",
    "                    'Winner': winner,\n",
    "                    'Delegates': delegates\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for scrapping the two special pages \n",
    "def scrape_election_page_special(state_nm):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    columns = soup.select('article.core-result')\n",
    "    \n",
    "    for column in columns:\n",
    "        county_name = None\n",
    "        table = column.select_one('table.cnn-pcl-1me6450')\n",
    "        rows = table.select('tr.cnn-pcl-1me6450')\n",
    "\n",
    "        for row in rows:\n",
    "            candidate_delegates = {} \n",
    "            name_element = row.select_one('span[data-testid=\"candidate-name\"]')\n",
    "            candidate = name_element.get_text(strip=True) if name_element else None\n",
    "\n",
    "            delegate_element = row.select_one('td[data-testid=\"delegates\"]')\n",
    "            try: # For some reason, this section is prone to error, hence the additional code block\n",
    "                delegates = int(delegate_element.get_text(strip=True)) if delegate_element else 0\n",
    "            except ValueError:\n",
    "                    delegates = 0\n",
    "\n",
    "            # Initialize the candidate in the dictionary if it doesn't exist\n",
    "            if candidate not in candidate_delegates:\n",
    "                candidate_delegates[candidate] = 0\n",
    "                \n",
    "            # Store the candidate-delegate pair in the dictionary\n",
    "            candidate_delegates[candidate] += delegates\n",
    "            if state_nm == 'american-samoa': # Simliar to 'North Carolina' above, just to handle the only two-word county \n",
    "                state = \"American Samoa\"\n",
    "            else: \n",
    "                state = soup.select_one('h2.header-2-AOgLYo.cnn-pcl-xk8c6r').get_text().split()[-1]\n",
    "            party_element = row.select_one('span[data-testid=\"party-label\"]')\n",
    "            party = party_element.get_text(strip=True).split(',')[0] if party_element else None\n",
    "\n",
    "            incumbent = 'Incumbent' in party_element.get_text(strip=True) if party_element else False\n",
    "            incumbent_status = 'Yes' if incumbent else 'No'\n",
    "\n",
    "            vote_percent_element = row.select_one('td[data-testid=\"votepercent\"]')\n",
    "            percentage = vote_percent_element.get_text(strip=True) if vote_percent_element else None\n",
    "            \n",
    "            vote_count_element = row.select_one('span[data-testid=\"votes\"]')\n",
    "            votes = 0\n",
    "            if vote_count_element:\n",
    "                try:\n",
    "                    votes = int(vote_count_element.get_text(strip=True).replace(',', ''))\n",
    "                except ValueError:\n",
    "                    votes = 0\n",
    "        \n",
    "            winner = 'Yes' if incumbent_status == 'Yes' else 'No'\n",
    "\n",
    "            delegates = candidate_delegates.get(candidate, 0)\n",
    "\n",
    "            # Conditional below is just to ensure driver only scraps Republican for Alaska, and Democratic for American Samao\n",
    "            if party and (state_nm == 'alaska' and party == 'Republican') or (state_nm == 'american-samoa' and party == 'Democratic'):\n",
    "                yield {\n",
    "                    'State': state,\n",
    "                    'County': county_name,\n",
    "                    'Candidate': candidate,\n",
    "                    'Party': party,\n",
    "                    'Incumbent': incumbent_status,\n",
    "                    'Votes': votes,\n",
    "                    'Percentage': percentage,\n",
    "                    'Winner': winner,\n",
    "                    'Delegates': delegates\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dem = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "suffix_dem = \"/democratic-presidential-primary\"\n",
    "prefix_rep = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "suffix_rep = \"/republican-presidential-primary\"\n",
    "\n",
    "combined_data = [] # This list will store all data returned by the functions  \n",
    "columns = ['State', 'County', 'Candidate', 'Party', 'Incumbent', 'Votes', 'Percentage', 'Winner', 'Delegates']\n",
    "combined_df = pd.DataFrame(columns=columns)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Append data for the Democratic Party \n",
    "for i in states_both:\n",
    "    # modify the state names\n",
    "    state_name = i.replace(\" \", \"-\")\n",
    "    link = f'{prefix_dem}{state_name}{suffix_dem}'\n",
    "    driver.get(link)\n",
    "\n",
    "    wait = WebDriverWait(driver, 1)  \n",
    "    button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "\n",
    "    # Right-click button element \n",
    "    have_button = True\n",
    "    button = driver.find_element(By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")\n",
    "\n",
    "    # Display all pages \n",
    "    while have_button: \n",
    "        try:\n",
    "            button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "            # Scrape the election page and add data to combined list\n",
    "            for election_data in scrape_election_page(state_name):\n",
    "                    if election_data is not None:\n",
    "                        combined_data.append(election_data) \n",
    "            button.click()\n",
    "        except TimeoutException:\n",
    "            have_button = False\n",
    "    \n",
    "    # Scrap data on last page (no right button)\n",
    "    for election_data in scrape_election_page(state_name):\n",
    "                if election_data is not None:\n",
    "                    combined_data.append(election_data) \n",
    "\n",
    "\n",
    "states_both.remove('iowa') # Removing 'Iowa' to prevent its Republican data from being scrapped  \n",
    "\n",
    "\n",
    "# Append data for the Republican Party \n",
    "for i in states_both:\n",
    "    # modify the state names\n",
    "    state_name = i.replace(\" \", \"-\")\n",
    "    link = f'{prefix_rep}{state_name}{suffix_rep}'\n",
    "    driver.get(link)\n",
    "\n",
    "    wait = WebDriverWait(driver, 1)  \n",
    "    button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "\n",
    "    # Right-click button element \n",
    "    have_button = True\n",
    "    button = driver.find_element(By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")\n",
    "\n",
    "    # Display all pages \n",
    "    while have_button: \n",
    "        try:\n",
    "            button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.rightButton.cnn-pcl-13b0kh1\")))\n",
    "            # Scrape the election page and add data to combined list\n",
    "            for election_data in scrape_election_page(state_name):\n",
    "                    if election_data is not None:\n",
    "                        combined_data.append(election_data)\n",
    "            button.click()\n",
    "        except TimeoutException:\n",
    "            have_button = False\n",
    "\n",
    "    for election_data in scrape_election_page(state_name):\n",
    "                if election_data is not None:\n",
    "                    combined_data.append(election_data) \n",
    "\n",
    "    \n",
    "# Append data for the two special webpages (Alaska and American Samoa)\n",
    "states_special = ['Alaska', 'American Samoa'] \n",
    "for i in states_special: \n",
    "        state_name = i.lower().replace(\" \", \"-\")\n",
    "        prefix = \"https://edition.cnn.com/election/2024/primaries-and-caucuses/results/\"\n",
    "        link = f'{prefix}{state_name}'\n",
    "        driver.get(link)\n",
    "        for election_data in scrape_election_page_special(state_name):\n",
    "            if election_data is not None:\n",
    "                combined_data.append(election_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10960, 9)\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.DataFrame(combined_data)     \n",
    "print(combined_df.shape)  \n",
    "combined_df.reset_index(inplace=True, drop=True) \n",
    "combined_df.index = combined_df.index + 1 \n",
    "combined_df = combined_df.fillna(value=pd.NA)\n",
    "combined_df['Votes'] = combined_df['Votes'].fillna(0).astype('int') # Filling 'Votes' column NaN with 0s, and converting data type to int for easier later access \n",
    "\n",
    "combined_df.to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
